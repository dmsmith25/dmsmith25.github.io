{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Gebru\n",
    "author: Dean Smith\n",
    "date: '2023-04-19'\n",
    "image: \"image.jpg\"\n",
    "description: \"A reflection of what I have learned from Timnit Gebru's experience and talk with our class.\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from Timnit Gebru"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr. Timnit Gebru is a renowned computer and data scientist who has been instrumental in the recent push for ethical AI practices. Dr. Gebru immigrated from Ethiopia to the United States where she studied electrical engineering and received her PhD in computer vision at Stanford University.\n",
    "\n",
    "\n",
    "After school, Dr. Gebru had an incredibly successful career working with electrical hardware for big tech companies including Apple, Microsoft, and Google. Her departure from Google came after leaders in Google's AI department refused to implement her requests for fair, unbiased, and ethical AI practices.\n",
    "\n",
    "\n",
    "As an African woman in a field dominated by white men, Dr. Gebru's perspective and work with Black in AI have pointed out numerous flaws and biases in big tech companies' AI practices. Dr. Gebru's work and bravery is truly inspiring and we are so thankful she has taken the time to speak with us.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020 Conference Talk Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the talk, Dr. Gebru points out various flaws with AI systems that are used to make life-changing decisions. The flaws she points out vary from how the data was collected to the purpose of the model itself. In many instances, companies gather data of people without their consent or use these models to infringe on people's rights.\n",
    "\n",
    "\n",
    "Dr. Gebru also talks about her experience as an African woman in a field dominated by white men. She references boards of AI directors and pictures of conferences. In this way, Dr. Gebru is able to rationalize why some of these biases exist in these systems. It is clear to see why Dr. Gebru's work has been so impactful given the lack of perspective in the computer science world.\n",
    "\n",
    "\n",
    "Dr. Gebru also touches on the ignorance to blindly trust AI especially in situations where the decisions it is making are life-altering. An area she focuses on is law enforcement and when it comes to convictions or facial recognition, law enforcement is trusting the advice of AI more than it should.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As aspiring computer/data scientists, what is one thing we can do to help fight these biases in AI?\n",
    "- In our class we have talked about how taking different statistics can lead to different conclusions about AI systems. During your Tutorial on FATE in Computer Vision talk in 2020, you referenced that there should be a regulatory agent like the FDA to monitor these systems. Is there any way we can ensure that such an agent does not add further bias to the problem?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Dr. Gebru's Talk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr. Gebru's argument in her talk focused mainly on the inequities of advanced AI technologies specifically on how they relate to eugenics. Dr. Gebru started with a background on eugenics as a study and how it has always been looked at as a \"science\". She cited numerous public figures in AI who use the same language as famous eugenics researchers from the 1900's. Next, Dr. Gebru broke down the main eugenics talking points and how they eerily resemble those of genetic and human modifications with advanced AI and technology.\n",
    "\n",
    "\n",
    "After establishing the similarities between both eugenics and advanced human modifications, Dr. Gebru began to explain the inequities behind these new technologies. She gave insight into how only people with desirable or \"fit\" genetics and intellect will have access to such technologies. In this way, Dr. Gebru portrays the dangers of eugenics becoming a prominent idea amongst the creators of these advanced human modifications.\n",
    "\n",
    "\n",
    "In a related but separate argument, Dr. Gebru dispels some of the hype around AGI and warns us about the dangers associated with AGI. She starts her argument by going through some notable computer scientists attempting to define what AGI is and none of them are able to produce a concrete answer. Here, Dr. Gebru makes her first point, which is that these big companies are trying to build something that they cannot clearly define themselves. Next, Dr. Gebru juxtaposes the rhetoric used to support AGI and that of religious texts. The point here is that the support of AGI is more similar to a religion than a science. In this way, Dr. Gebru explains how these companies are trying to build a god which can have some dire consequences.\n",
    "\n",
    "\n",
    "In regards to the AGI argument, I agree with Dr. Gebru in some areas such as using machine learning models for specific use cases would be a much better option than a do-it-all program. In the talk, Dr. Gebru referenced a language translating model that did better than google translate which is utilized by Chat-GPT. I feel that this is a great example to show how a do-it-all program is not needed.\n",
    "\n",
    "\n",
    "Additionally, I agree with Dr. Gebru's cautiousness towards these big companies deciding how and on what data these large models are trained. The production of AGI reminds me of the 2008 housing crisis and how despite huge banks with rational and fiscally \"responsible\" people, their negligence has catastrophic consequences. I fear, along with Dr. Gebru, that putting all of our trust in businesses whose sole purpose is to increase share-holder value, is incredibly dangerous. Lastly, I feel that there should be a way for us to check these large companies to make sure they are being ethical and cautious in their development of AGI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with Dr. Gebru and her work, I found it insightful how software models which make life-altering choices are designed by groups where minorities are underrepresented and therefore miss some of the biases from improper data-collection. When creating programs before my time with Dr. Gebru, I never really took into account any biases that could exist within the program. I feel that this part has been quite worrisome for me. I do not want to be involved in making a product that can disproportionately harm people based on factors they cannot control. In one of Dr. Gebru's talks she mentioned having a department designed to make sure there are no biases in programs. I feel that this would be a great addition to the computer science world similar to how the FDA regulates food. An agency that all machine learning models must go through to publicize or use the model would greatly benefit those that are marginalized and also computer scientists for not having to harm people's lives before realizing there are biases in their model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ml-0451')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "debe06cc0f9553f110b64dc3926c05df82dae2145b852c8422b9c04315589dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
